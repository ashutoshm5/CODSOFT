# -*- coding: utf-8 -*-
"""Credit card fraud detection model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GIIU8dfuXK-LO1JCkHwL2Y9Ybh9OTKmJ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid", rc={"figure.figsize": (8, 5)})

# Classifiers
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Model selection and metrics
from sklearn.model_selection import train_test_split, KFold
try:
    from sklearn.model_selection import StratifiedGroupKFold
except ImportError:
    StratifiedGroupKFold = None

from sklearn.metrics import (
    precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
)

import warnings
warnings.filterwarnings("ignore")

from google.colab import files
print("Choose your CSV file to upload...")
uploaded = files.upload()         # pick your file, e.g., fraudtest.csv or creditcard.csv
csv_filename = next(iter(uploaded.keys()))
print("Uploaded:", csv_filename)

# Load the datasheet
df = pd.read_csv(csv_filename)
display(df.head())
print("Shape:", df.shape)
print("Columns:", df.columns.tolist())

df.describe()

df.isnull().sum().max()

df.columns

target = "is_fraud"

vc = df[target].value_counts(dropna=False)
n0 = vc.get(0, 0)  # non-fraud count
n1 = vc.get(1, 0)  # fraud count

print("NOT IN CONDITION OF FRAUD", round(n0 / len(df) * 100, 2), "% of the dataset")
print("ARE IN CONDITION OF FRAUD",    round(n1 / len(df) * 100, 2), "% of the dataset")

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x="is_fraud", data=df)  # explicitly name x
plt.title("Class Distribution\n(0: Not Fraud | 1: Fraud)", fontsize=14)
plt.xlabel("is_fraud")
plt.ylabel("Count")
plt.show()

fig, ax = plt.subplots(1,2, figsize=(20,10))
amount_value = df['amt'].values
# Assuming 'trans_date_trans_time' can be used as a proxy for time
time_value = df['unix_time'].values

sns.histplot(amount_value, ax=ax[0], color='r', kde=True)
ax[0].set_title('Distribution of Transaction Amount', fontsize=14)
ax[0].set_xlabel('Amount')
ax[0].set_ylabel('Frequency')


sns.histplot(time_value, ax=ax[1], color='b', kde=True)
ax[1].set_title('Distribution of Transaction Time', fontsize=14)
ax[1].set_xlabel('Time (Unix Timestamp)')
ax[1].set_ylabel('Frequency')


plt.show()

from  sklearn.preprocessing import StandardScaler, RobustScaler

standard_scaleer = StandardScaler()
robust_scaler = RobustScaler()

df['scaled_amt'] = robust_scaler.fit_transform(df['amt'].values.reshape(-1, 1))
df['scaled_unix_time'] = robust_scaler.fit_transform(df['unix_time'].values.reshape(-1, 1))

df.drop(['amt', 'unix_time'], axis=1, inplace=True)
scaled_amount = df['scaled_amt']
scaled_time = df['scaled_unix_time']

df.drop(['scaled_amt', 'scaled_unix_time'], axis=1, inplace=True)
df.insert(0, 'scaled_amt', scaled_amount)
df.insert(1, 'scaled_unix_time', scaled_time)

df.head() #amount and time are now scaled

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit
#assign x,y variables

X = df.drop(target, axis=1)
y = df[target]
df[target].value_counts()

#Here we are going to shuffle the data before creating the subsamples

df = df.sample(frac=1).reset_index(drop=True)

fraud_df = df[df[target] == 1]
non_fraud_df = df[df[target] == 0][:492]

normal_distributed_df = pd.concat([fraud_df, non_fraud_df])

#shuffle dataframe rows
Distribution_df = normal_distributed_df.sample(frac=1, random_state=42)

Distribution_df.head()

import matplotlib.pyplot as plt
fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=False)

sns.boxplot(x="is_fraud", y="trans_num", data=Distribution_df, ax=axes[0])
axes[0].set_title("Transaction Number vs Fraud", fontsize=14)

sns.boxplot(x="is_fraud", y="lat", data=Distribution_df, ax=axes[1])
axes[1].set_title("Latitude vs Fraud", fontsize=14)

sns.boxplot(x="is_fraud", y="long", data=Distribution_df, ax=axes[2])
axes[2].set_title("Longitude vs Fraud", fontsize=14)

plt.tight_layout()
plt.show()

from scipy.stats import norm

f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 8))

transaction_distribution = Distribution_df['scaled_amt'].loc[Distribution_df['is_fraud'] == 1].values
sns.distplot(transaction_distribution, ax=ax1, fit=norm, kde=False, color='yellow')
ax1.set_title('Scaled Amount Distribution \n (Fraudulent Transactions)', fontsize=14)

lat_distribution = Distribution_df['lat'].loc[Distribution_df['is_fraud'] == 1].values
sns.distplot(lat_distribution, ax=ax2, fit=norm, kde=False, color='green')
ax2.set_title('Latitude Distribution \n (Fraudulent Transactions)', fontsize=14)

long_distribution = Distribution_df['long'].loc[Distribution_df['is_fraud'] == 1].values
sns.distplot(long_distribution, ax=ax3, fit=norm, kde=False, color='red')
ax3.set_title('Longitude Distribution \n (Fraudulent Transactions)', fontsize=14)


plt.tight_layout()
plt.show()

# ============================================
# IQR-based outlier analysis and handling
# Works with your dataset where target = "is_fraud"
# ============================================

import numpy as np
import pandas as pd

# ---------- CONFIG ----------
TARGET = "is_fraud"                      # your label column
FEATURES = ["scaled_amt", "scaled_unix_time"]               # features to process; edit to your actual columns
IQR_K = 1.5                             # 1.5 = Tukey rule; higher -> fewer outliers
MODE = "cap"                             # "cap" to winsorize, or "drop" to remove rows
# ----------------------------

def iqr_caps_for_fraud(df, feature, target=TARGET, iqr_k=IQR_K):
    """
    Compute IQR-based caps (lower/upper) using FRAUD rows only (target == 1).
    Returns a dict with quartiles, IQR, cut_off, caps, and outlier list among fraud rows.
    """
    vals = df.loc[df[target] == 1, feature].dropna().values
    if vals.size == 0:
        raise ValueError(f"No fraud rows or all NaN for feature '{feature}'.")

    q25 = np.percentile(vals, 25)
    q75 = np.percentile(vals, 75)
    iqr = q75 - q25
    cut_off = iqr * iqr_k
    lowercap = q25 - cut_off
    uppercap = q75 + cut_off

    outliers = [v for v in vals if (v < lowercap) or (v > uppercap)]

    return {
        "q25": q25, "q75": q75, "iqr": iqr, "cut_off": cut_off,
        "lowercap": lowercap, "uppercap": uppercap,
        "outliers_list": outliers, "n_outliers": len(outliers)
    }

def drop_outliers_iqr(df, feature, lowercap, uppercap):
    """Drop rows where feature is outside [lowercap, uppercap]."""
    mask = (df[feature] >= lowercap) & (df[feature] <= uppercap)
    return df.loc[mask].copy()

def cap_outliers_iqr(df, feature, lowercap, uppercap):
    """Winsorize feature to [lowercap, uppercap] and return a new DataFrame."""
    out = df.copy()
    out[feature] = out[feature].clip(lower=lowercap, upper=uppercap)
    return out

# Safety checks
missing_feats = [f for f in FEATURES if f not in df.columns]
if missing_feats:
    raise ValueError(f"These FEATURES are not in your DataFrame: {missing_feats}")

if TARGET not in df.columns:
    raise ValueError(f"TARGET column '{TARGET}' not found in DataFrame.")

print(f"Starting shape: {df.shape}")
df_proc = df.copy()

for feat in FEATURES:
    info = iqr_caps_for_fraud(df_proc, feature=feat, target=TARGET, iqr_k=IQR_K)

    print("\n" + "="*60)
    print(f"Feature: {feat}")
    print(f"First Quartile 25: {info['q25']:.6f} | Third Quartile 75: {info['q75']:.6f}")
    print(f"Range (IQR): {info['iqr']:.6f}")
    print(f"Cut Off (IQR * {IQR_K}): {info['cut_off']:.6f}")
    print(f"{feat} Lowercap: {info['lowercap']:.6f}")
    print(f"{feat} Uppercap: {info['uppercap']:.6f}")
    print(f"Feature {feat} Outliers among FRAUD rows: {info['n_outliers']}")

    # Apply chosen mode to the WHOLE dataset for this feature
    if MODE.lower() == "drop":
        before = len(df_proc)
        df_proc = drop_outliers_iqr(df_proc, feat, info["lowercap"], info["uppercap"])
        after = len(df_proc)
        print(f"Rows after DROP on {feat}: {after} (removed {before - after})")

    elif MODE.lower() == "cap":
        df_proc = cap_outliers_iqr(df_proc, feat, info["lowercap"], info["uppercap"])
        print(f"Applied CAP on {feat}; row count unchanged: {len(df_proc)}")

    else:
        raise ValueError("MODE must be 'cap' or 'drop'.")

print("\n" + "="*60)
print("Final processed shape:", df_proc.shape)

# Optional: show class distribution before/after
def class_pct(series):
    vc = series.value_counts(dropna=False)
    total = vc.sum()
    pct = {k: round(v/total*100, 4) for k, v in vc.to_dict().items()}
    return pct

print("\nClass distribution (original):", class_pct(df[TARGET]))
print("Class distribution (processed):", class_pct(df_proc[TARGET]))

# If you want the processed DataFrame to replace df, uncomment:
# df = df_proc

f, (ax1, ax2,  ax3) = plt.subplots(1,3, figsize=(18, 8))

colors = ['red', 'green']

sns.boxplot(x="is_fraud", y="scaled_amt", data=df_proc, ax=ax1, palette=colors)
ax1.set_title("Scaled Amount vs Fraud", fontsize=14)
ax1.annotate("Find extreme \n outliers", xy=(0.98, -17.5), xytext=(0,-12), arrowprops=dict(facecolor='black'),fontsize=14)

sns.boxplot(x="is_fraud", y="scaled_unix_time", data=df_proc, ax=ax2, palette=colors)
ax2.set_title("Scaled Time vs Fraud", fontsize=14)
ax2.annotate('Find extreme \n outliers', xy=(0.98, -17.5), xytext=(0,-12), arrowprops=dict(facecolor='black'),fontsize=14)

sns.boxplot(x="is_fraud", y="city_pop", data=df_proc, ax=ax3, palette=colors)
ax3.set_title("City Population vs Fraud", fontsize=14)
ax3.annotate('Find extreme \n outliers', xy=(0.98, -17.5), xytext=(0,-12), arrowprops=dict(facecolor='black'),fontsize=14)

plt.show()

x = Distribution_df.drop(target, axis=1)
y = Distribution_df[target]

# Drop non-numeric columns
x = x.drop(['trans_date_trans_time', 'cc_num', 'merchant', 'first', 'last', 'gender', 'street', 'city', 'state', 'job', 'dob', 'trans_num', 'category'], axis=1)


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

X_train = x_train.values
X_test = x_test.values
y_train = y_train.values
y_test = y_test.values


# Convert y_train and y_test to pandas Series
y_train = pd.Series(y_train)
y_test = pd.Series(y_test)


classifiers = {
    "Logisitic Regression": LogisticRegression(),
    "Support Vector Machine": SVC(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}

from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer

for key, classifier in classifiers.items():
    classifier.fit(X_train, y_train)
    classifier.fit(X_train, y_train)
    training_score = cross_val_score(classifier, X_train, y_train, cv=5)
    print("Classifier:", key, "Has a training score of", round(training_score.mean(), 2) * 100, "% accuracy score")
    test_score = classifier.score(X_test, y_test)
    print("Classifier:", key, "Has a test score of", round(test_score, 2) * 100, "% accuracy score")
    print("="*30)

#use fridsearchCV to find the best parameters.
from sklearn.model_selection import GridSearchCV

#Logistic regression
logistic_regression_param = {"penalty":['l1','l2'], "C": [0.001, 0.01, 0.1, 1, 10, 100, 1000]}

lg = GridSearchCV(LogisticRegression(), logistic_regression_param)
lg.fit(X_train, y_train)
print("Best parameters for Logistic Regression:", lg.best_params_)
log_param = lg.best_estimator_

descision_tress_param = {"criterion": ["gini", "entropy"], "max_depth": [4, 6, 8, 10]}
dt = GridSearchCV(DecisionTreeClassifier(), descision_tress_param)
dt.fit(X_train, y_train)

tree_param = dt.best_estimator_
print("Best parameters for Decision Tree:", dt.best_params_)
print(log_param)
print(tree_param)

"""# Task
Load the data from "test.csv", preprocess it, make predictions using the trained Logistic Regression and Decision Tree models, evaluate the model performance on the test set, and summarize the results to determine if the task of building a model to detect fraudulent credit card transactions is complete.

## Load test data

### Subtask:
Load the data from the `test.csv` file into a pandas DataFrame.
"""

# Separate features and target
X_test_processed = df_test.drop(target, axis=1)
y_test_processed = df_test[target]

display(X_test_processed.head())
print("Shape of processed test features:", X_test_processed.shape)
print("Shape of processed test target:", y_test_processed.shape)

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

# Evaluate Logistic Regression
print("Logistic Regression Performance:")
print("Precision:", precision_score(y_test_processed, log_reg_pred))
print("Recall:", recall_score(y_test_processed, log_reg_pred))
print("F1-score:", f1_score(y_test_processed, log_reg_pred))
print("ROC AUC:", roc_auc_score(y_test_processed, log_reg_pred))

print("\n" + "="*30 + "\n")

# Evaluate Decision Tree
print("Decision Tree Performance:")
print("Precision:", precision_score(y_test_processed, tree_pred))
print("Recall:", recall_score(y_test_processed, tree_pred))
print("F1-score:", f1_score(y_test_processed, tree_pred))
print("ROC AUC:", roc_auc_score(y_test_processed, tree_pred))

# Make predictions using the trained models
log_reg_pred = log_param.predict(X_test_processed)
tree_pred = tree_param.predict(X_test_processed)

print("Logistic Regression predictions:", log_reg_pred[:10])
print("Decision Tree predictions:", tree_pred[:10])

"""**Reasoning**:
Load the test data into a pandas DataFrame.


"""